{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tratamiento de los datos </h2>\n",
    "\n",
    "<h3>Carga de los datos y de las rutas de las imagenes</h3>\n",
    "\n",
    "En primer lugar elaboraremos un dataframe elaborado con Pandas en el que incluiremos las rutas de las imagenes, su identificación, la clase de cancer, su edad, su tipo de operación si es que ha realizado alguna y su supervivencia.\n",
    "Tambien serán eliminados los campos que no sean importantes como las identificaciones de otros años.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory_path = 'G:\\Dataset'\n",
    "os.chdir(directory_path)\n",
    "\n",
    "survival_path = os.path.join(directory_path, 'survival_info.csv')\n",
    "survival_dataframe = pd.read_csv(survival_path, header=0, index_col='Brats20ID')\n",
    "survival_dataframe.index.names = ['ID']\n",
    "\n",
    "grade_dataframe = os.path.join(directory_path, 'name_mapping.csv')\n",
    "grade_dataframe = pd.read_csv(grade_dataframe, header=0, index_col='BraTS_2020_subject_ID')\n",
    "grade_dataframe.index.names = ['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>age</th>\n",
       "      <th>survival_days</th>\n",
       "      <th>extent_of_resection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>369</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>HGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448</td>\n",
       "      <td>GTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>61.223203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.874114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.975000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>54.244250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>61.471000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>69.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>86.652000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade         age survival_days extent_of_resection\n",
       "count    369  236.000000           236                 129\n",
       "unique     2         NaN           218                   2\n",
       "top      HGG         NaN           448                 GTR\n",
       "freq     293         NaN             3                 119\n",
       "mean     NaN   61.223203           NaN                 NaN\n",
       "std      NaN   11.874114           NaN                 NaN\n",
       "min      NaN   18.975000           NaN                 NaN\n",
       "25%      NaN   54.244250           NaN                 NaN\n",
       "50%      NaN   61.471000           NaN                 NaN\n",
       "75%      NaN   69.200000           NaN                 NaN\n",
       "max      NaN   86.652000           NaN                 NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = grade_dataframe.join(survival_dataframe)\n",
    "dataframe.drop(columns=['BraTS_2017_subject_ID', 'BraTS_2018_subject_ID', 'TCGA_TCIA_subject_ID', 'BraTS_2019_subject_ID'], inplace=True)\n",
    "dataframe.rename(columns={'Grade':'grade', 'Age':'age','Survival_days':'survival_days','Extent_of_Resection':'extent_of_resection'}, inplace=True)\n",
    "dataframe.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_path(dataframe, directory_path):\n",
    "    '''\n",
    "    '''\n",
    "    images=['_t1.nii', '_t1ce.nii', '_t2.nii', '_flair.nii']\n",
    "    for ID in dataframe.index:\n",
    "        dataframe.at[ID, 't1'] = os.path.join(directory_path, ID, ID+images[0])\n",
    "        dataframe.at[ID, 't1ce'] = os.path.join(directory_path, ID, ID+images[1])\n",
    "        dataframe.at[ID, 't2'] = os.path.join(directory_path, ID, ID+images[2])\n",
    "        dataframe.at[ID, 'flair'] = os.path.join(directory_path, ID, ID+images[3])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>age</th>\n",
       "      <th>survival_days</th>\n",
       "      <th>extent_of_resection</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1ce</th>\n",
       "      <th>t2</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_001</th>\n",
       "      <td>HGG</td>\n",
       "      <td>60.463</td>\n",
       "      <td>289</td>\n",
       "      <td>GTR</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_002</th>\n",
       "      <td>HGG</td>\n",
       "      <td>52.263</td>\n",
       "      <td>616</td>\n",
       "      <td>GTR</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_003</th>\n",
       "      <td>HGG</td>\n",
       "      <td>54.301</td>\n",
       "      <td>464</td>\n",
       "      <td>GTR</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_004</th>\n",
       "      <td>HGG</td>\n",
       "      <td>39.068</td>\n",
       "      <td>788</td>\n",
       "      <td>GTR</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_005</th>\n",
       "      <td>HGG</td>\n",
       "      <td>68.493</td>\n",
       "      <td>465</td>\n",
       "      <td>GTR</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     grade     age survival_days extent_of_resection  \\\n",
       "ID                                                                     \n",
       "BraTS20_Training_001   HGG  60.463           289                 GTR   \n",
       "BraTS20_Training_002   HGG  52.263           616                 GTR   \n",
       "BraTS20_Training_003   HGG  54.301           464                 GTR   \n",
       "BraTS20_Training_004   HGG  39.068           788                 GTR   \n",
       "BraTS20_Training_005   HGG  68.493           465                 GTR   \n",
       "\n",
       "                                                                     t1  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                   t1ce  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                     t2  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                  flair  \n",
       "ID                                                                       \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...  \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...  \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...  \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...  \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_image_path(dataframe, directory_path)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocesado de los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>age</th>\n",
       "      <th>survival_days</th>\n",
       "      <th>extent_of_resection</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1ce</th>\n",
       "      <th>t2</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_260</th>\n",
       "      <td>LGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_261</th>\n",
       "      <td>LGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_262</th>\n",
       "      <td>LGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_263</th>\n",
       "      <td>LGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_264</th>\n",
       "      <td>LGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     grade  age survival_days extent_of_resection  \\\n",
       "ID                                                                  \n",
       "BraTS20_Training_260   LGG  NaN           NaN                 NaN   \n",
       "BraTS20_Training_261   LGG  NaN           NaN                 NaN   \n",
       "BraTS20_Training_262   LGG  NaN           NaN                 NaN   \n",
       "BraTS20_Training_263   LGG  NaN           NaN                 NaN   \n",
       "BraTS20_Training_264   LGG  NaN           NaN                 NaN   \n",
       "\n",
       "                                                                     t1  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_260  G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...   \n",
       "BraTS20_Training_261  G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...   \n",
       "BraTS20_Training_262  G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...   \n",
       "BraTS20_Training_263  G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...   \n",
       "BraTS20_Training_264  G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...   \n",
       "\n",
       "                                                                   t1ce  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_260  G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...   \n",
       "BraTS20_Training_261  G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...   \n",
       "BraTS20_Training_262  G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...   \n",
       "BraTS20_Training_263  G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...   \n",
       "BraTS20_Training_264  G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...   \n",
       "\n",
       "                                                                     t2  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_260  G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...   \n",
       "BraTS20_Training_261  G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...   \n",
       "BraTS20_Training_262  G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...   \n",
       "BraTS20_Training_263  G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...   \n",
       "BraTS20_Training_264  G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...   \n",
       "\n",
       "                                                                  flair  \n",
       "ID                                                                       \n",
       "BraTS20_Training_260  G:\\Dataset\\BraTS20_Training_260\\BraTS20_Traini...  \n",
       "BraTS20_Training_261  G:\\Dataset\\BraTS20_Training_261\\BraTS20_Traini...  \n",
       "BraTS20_Training_262  G:\\Dataset\\BraTS20_Training_262\\BraTS20_Traini...  \n",
       "BraTS20_Training_263  G:\\Dataset\\BraTS20_Training_263\\BraTS20_Traini...  \n",
       "BraTS20_Training_264  G:\\Dataset\\BraTS20_Training_264\\BraTS20_Traini...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizando los datos podemos observar que todos los pacientes con un grado de tumor bajo no tienen datos de supervivencia ni de\n",
    "#extracción del tumor, ni edad. Esto es en gran medida porque estos pacientes tienen un pronostico bastante favorable [1] y la mayoria no necesita cirugia.\n",
    "#Por eso asumiremos que ninguno de ellos se realizo cirugía, su edad será fijada de forma aleatoria entre el minimo y el maximo de las edades y el tiempo de supervivencia sera aleatorio entre \n",
    "#https://www.analesdepediatria.org/es-gliomas-bajo-grado-revision-10-articulo-S1695403314000873#:~:text=La%20supervivencia%20global%20fue%20del%2088%2C3%25%2C%20con%20una,fue%20del%2083%2C7%25.\n",
    "#https://ascopubs.org/doi/full/10.1200/JOP.2016.018622#:~:text=A%20larger%20study%20of%20216,of%20resection%20was%20%3C%2090%25.\n",
    "\n",
    "#Segun el estudio [2] un 76% de las personas con una extirpación de menos del 90% del tumor sobrevivieron más de 5 años. Por lo que\n",
    "#como asumimos que estas personas no se realizaron cirugía ya que no tenemos datos, calcularemos el tiempo de supervivencia como un número\n",
    "#aleatorio entre 4 y 7 teniendo un 24% de ser entre 4-5 y un 76% de ser entre 5-7\n",
    "#En cuanto a la edad esta será calcula aleatoriamente en el rango de la media del resto de las edades con la desviacion tipica [media-dt, media+dt] \n",
    "dataframe.loc[(dataframe['grade'] != 'HGG') & (pd.isna(dataframe['age']) == True)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_survival(dataframe):\n",
    "    '''\n",
    "    '''\n",
    "    a=4\n",
    "    b=5\n",
    "    c=7\n",
    "    probability_low = 24\n",
    "    indexes = dataframe.loc[(pd.isna(dataframe['age']) == True)].index\n",
    "    survival_fill = pd.DataFrame([0 for i in range(0, len(indexes))], columns=['fill'], index=indexes)\n",
    "    for i in indexes.values:\n",
    "        low = np.random.randint((a*365), high=(b*365)+1)\n",
    "        high = np.random.randint((b*365), high=(c*365)+1)\n",
    "        probability = np.random.randint(1, high=101)\n",
    "        \n",
    "        if probability <= probability_low:\n",
    "            survival_fill.loc[i, 'fill'] = low\n",
    "        else:\n",
    "            survival_fill.loc[i, 'fill'] = high\n",
    "            \n",
    "    return survival_fill['fill']\n",
    "\n",
    "def generate_age(dataframe):\n",
    "    '''\n",
    "    '''\n",
    "    indexes = dataframe.loc[(pd.isna(dataframe['age']) == True)].index\n",
    "    age_fill = pd.DataFrame([0 for i in range(0, len(indexes))], columns=['fill'], index=indexes)\n",
    "    \n",
    "    ages = dataframe.loc[pd.isna(dataframe['age']) == False]\n",
    "    age_mean = np.round(ages.mean(), 3)\n",
    "    age_std = np.round(ages.std(), 3)\n",
    "    minimo = age_mean-age_std\n",
    "    maximo = age_mean+age_std\n",
    "    \n",
    "    for i in indexes.values:\n",
    "        random = np.round(np.random.uniform(minimo, maximo), 3)\n",
    "        age_fill.loc[i, 'fill'] = random\n",
    "        \n",
    "    return age_fill['fill']\n",
    "\n",
    "def normalize_age(dataframe):\n",
    "    '''\n",
    "    '''\n",
    "    max_value = dataframe['age'].max()\n",
    "    min_value = dataframe['age'].min()\n",
    "    dataframe['age'] = (dataframe['age'] - min_value) / (max_value - min_value)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_6480\\3122688624.py:29: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  age_mean = np.round(ages.mean(), 3)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_6480\\3122688624.py:30: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  age_std = np.round(ages.std(), 3)\n"
     ]
    }
   ],
   "source": [
    "dataframe['survival_days'].fillna(generate_survival(dataframe), inplace=True)\n",
    "dataframe['age'].fillna(generate_age(dataframe), inplace=True)\n",
    "#dataframe = normalize_age(dataframe)\n",
    "\n",
    "grade_encoding = {'LGG':0, 'HGG':1}\n",
    "dataframe['grade'] = dataframe['grade'].replace(grade_encoding)\n",
    "\n",
    "dataframe.drop(dataframe.loc[dataframe['survival_days'] == 'ALIVE (361 days later)'].index, axis=0, inplace=True)\n",
    "dataframe = dataframe.astype({\"grade\": int, 'survival_days':int})\n",
    "\n",
    "survival_encoding = {'< 1 year':0, '1-5 years':1, '+5 years':2}\n",
    "for i in dataframe.index:\n",
    "    if dataframe['survival_days'].loc[i] < 365:\n",
    "        dataframe.loc[[i],['survival_days']] = survival_encoding['< 1 year']\n",
    "    elif dataframe['survival_days'].loc[i] < 1825:\n",
    "        dataframe.loc[[i],['survival_days']] = survival_encoding['1-5 years']\n",
    "    else:\n",
    "        dataframe.loc[[i],['survival_days']] = survival_encoding['+5 years']\n",
    "        \n",
    "dataframe['extent_of_resection'].fillna('NONE', inplace=True)\n",
    "dataframe = pd.get_dummies(dataframe, columns=['extent_of_resection'], prefix='resection_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>age</th>\n",
       "      <th>survival_days</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1ce</th>\n",
       "      <th>t2</th>\n",
       "      <th>flair</th>\n",
       "      <th>resection__GTR</th>\n",
       "      <th>resection__NONE</th>\n",
       "      <th>resection__STR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_001</th>\n",
       "      <td>1</td>\n",
       "      <td>60.463</td>\n",
       "      <td>0</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_002</th>\n",
       "      <td>1</td>\n",
       "      <td>52.263</td>\n",
       "      <td>1</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_003</th>\n",
       "      <td>1</td>\n",
       "      <td>54.301</td>\n",
       "      <td>1</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_004</th>\n",
       "      <td>1</td>\n",
       "      <td>39.068</td>\n",
       "      <td>1</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BraTS20_Training_005</th>\n",
       "      <td>1</td>\n",
       "      <td>68.493</td>\n",
       "      <td>1</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      grade     age  survival_days  \\\n",
       "ID                                                   \n",
       "BraTS20_Training_001      1  60.463              0   \n",
       "BraTS20_Training_002      1  52.263              1   \n",
       "BraTS20_Training_003      1  54.301              1   \n",
       "BraTS20_Training_004      1  39.068              1   \n",
       "BraTS20_Training_005      1  68.493              1   \n",
       "\n",
       "                                                                     t1  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                   t1ce  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                     t2  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                                                                  flair  \\\n",
       "ID                                                                        \n",
       "BraTS20_Training_001  G:\\Dataset\\BraTS20_Training_001\\BraTS20_Traini...   \n",
       "BraTS20_Training_002  G:\\Dataset\\BraTS20_Training_002\\BraTS20_Traini...   \n",
       "BraTS20_Training_003  G:\\Dataset\\BraTS20_Training_003\\BraTS20_Traini...   \n",
       "BraTS20_Training_004  G:\\Dataset\\BraTS20_Training_004\\BraTS20_Traini...   \n",
       "BraTS20_Training_005  G:\\Dataset\\BraTS20_Training_005\\BraTS20_Traini...   \n",
       "\n",
       "                      resection__GTR  resection__NONE  resection__STR  \n",
       "ID                                                                     \n",
       "BraTS20_Training_001               1                0               0  \n",
       "BraTS20_Training_002               1                0               0  \n",
       "BraTS20_Training_003               1                0               0  \n",
       "BraTS20_Training_004               1                0               0  \n",
       "BraTS20_Training_005               1                0               0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dataframe.loc[dataframe['grade'] == 1].count()[0] - dataframe.loc[dataframe['grade'] == 0].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(diff):\n",
    "    dataframe.drop(dataframe.loc[dataframe['grade'] == 1].index[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Carga y preprocesado de las imagenes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#HU -1000 (aire) 800 (huesos son 1000, asi los evitamos)\n",
    "class Data_generator():\n",
    "    \"\"\"\n",
    "    Data generator\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, train_size, width, height, depth, slices=10):\n",
    "        self.dataframe = dataframe\n",
    "        self.train_size = train_size\n",
    "        self.slices = slices\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.depth = depth\n",
    "        \n",
    "    def generate_split_indexes(self):\n",
    "        '''\n",
    "        '''\n",
    "        np.random.seed(1)\n",
    "        permutation = np.random.permutation(len(self.dataframe))\n",
    "        index = int(len(self.dataframe) * self.train_size)\n",
    "        train_index = permutation[:index]\n",
    "        test_index = permutation[index:]\n",
    "        \n",
    "        index = int(index * self.train_size)\n",
    "        train_index, valid_index = train_index[:index], train_index[index:]\n",
    "        \n",
    "        return train_index, valid_index, test_index\n",
    "    \n",
    "    def read_scan(self, filepath):\n",
    "        \"\"\"Read and load volume\"\"\"\n",
    "        # Read file\n",
    "        img = nib.load(filepath)\n",
    "        # Rotate the image to a fixed axes\n",
    "        img = nib.as_closest_canonical(img)\n",
    "        # Get raw data\n",
    "        img = img.get_fdata()\n",
    "        return img\n",
    "    \n",
    "    def normalize(self, img):\n",
    "        \"\"\"Normalize the volume\"\"\"\n",
    "        minimun = -1000\n",
    "        maximun = 800\n",
    "        img[img < minimun] = minimun\n",
    "        img[img > maximun] = maximun\n",
    "        #img = (img - minimun) / (maximun - minimun)\n",
    "        img = img.astype(\"float32\")\n",
    "        return img\n",
    "    \n",
    "    def resize_volume(self, img):\n",
    "        # Get current depth\n",
    "        current_depth = img.shape[-1]\n",
    "        current_width = img.shape[0]\n",
    "        current_height = img.shape[1]\n",
    "        # Compute depth factor\n",
    "        depth = current_depth / self.depth\n",
    "        width = current_width / self.width\n",
    "        height = current_height / self.height\n",
    "        depth_factor = 1 / depth\n",
    "        width_factor = 1 / width\n",
    "        height_factor = 1 / height\n",
    "        \n",
    "        # Resize across z-axis\n",
    "        img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "        return img        \n",
    "    \n",
    "    def preprocess_image(self, path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        # Read scan\n",
    "        volume = self.read_scan(path)\n",
    "        # Normalize\n",
    "        volume = self.normalize(volume)\n",
    "        #volume = self.resize_volume(volume)\n",
    "        \n",
    "        return volume[:,:,-90::30]\n",
    "    \n",
    "    def generate_data(self, indexes, is_training, output, batch_size=32):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        # arrays to store our batched data\n",
    "        t1, t1ce, t2, flair, text, labels = [], [], [], [], [], []\n",
    "        while True:\n",
    "            for index in indexes:\n",
    "                patient = self.dataframe.iloc[index]\n",
    "                \n",
    "                t1_path = patient['t1']\n",
    "                t1ce_path = patient['t1ce']\n",
    "                t2_path = patient['t2']\n",
    "                flair_path = patient['flair']\n",
    "                for i in range(4):\n",
    "\n",
    "                    if(i == 0):\n",
    "                        t1ce.append(self.preprocess_image(t1_path))\n",
    "                    elif(i == 1):\n",
    "                        t1ce.append(self.preprocess_image(t1ce_path))\n",
    "                    elif(i == 2):\n",
    "                        t1ce.append(self.preprocess_image(t2_path))\n",
    "                    elif(i == 3):\n",
    "                        t1ce.append(self.preprocess_image(flair_path))\n",
    "                    \n",
    "                    if(output == 'grade'):\n",
    "                        labels.append(to_categorical(patient['grade'], 2))\n",
    "                        text.append(patient[['age', 'resection__GTR', 'resection__NONE', 'resection__STR']])\n",
    "                    else:\n",
    "                        labels.append(to_categorical(patient['survival_days'], 3))\n",
    "                        text.append(patient[['age', 'resection__GTR', 'resection__NONE', 'resection__STR']])\n",
    "                    \n",
    "\n",
    "                    # Lo que hace yield es crear un generador, es decir, cuando se ejecute este trozo de código no se ejecuta\n",
    "                    # instantaneamente, sino que más adelante cuando internamente el programa llame a next se ejecutará el código\n",
    "                    # hasta que se encuentre un yield y ahí parará. Con el siguiente next volvera a hacer una iteración y así.\n",
    "                    if len(t1ce) >= batch_size:\n",
    "                        yield [np.float32(t1ce), np.float32(text)], np.float32(labels)\n",
    "                        t1, t1ce, t2, flair, text, labels = [], [], [], [], [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.80\n",
    "image_width = 240\n",
    "image_height = 240\n",
    "image_depth_o = 150\n",
    "slices_step = 50\n",
    "image_depth = (image_depth_o -1)//slices_step +1\n",
    "\n",
    "data_generator = Data_generator(dataframe, train_size, image_width, image_height, image_depth, slices_step)\n",
    "train_index, valid_index, test_index = data_generator.generate_split_indexes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_rama_grado(modelo, input_text):\n",
    "    \"\"\"\n",
    "    crea la rama que predice el grado del tumor\n",
    "    \"\"\"\n",
    "    rama_grado = layers.Concatenate()([modelo, input_text])\n",
    "\n",
    "    rama_grado = layers.Dense(256, activation=\"relu\")(rama_grado)\n",
    "    rama_grado = layers.BatchNormalization()(rama_grado)\n",
    "    rama_grado = layers.Dropout(0.3)(rama_grado)\n",
    "    rama_grado = layers.Dense(512, activation=\"relu\")(rama_grado)\n",
    "    rama_grado = layers.Dense(2)(rama_grado)\n",
    "    rama_grado = layers.Activation(\"softmax\", name=\"grade\")(rama_grado)\n",
    "\n",
    "    return rama_grado\n",
    "\n",
    "def crear_rama_supervivencia(modelo, input_text):\n",
    "    \"\"\"\n",
    "    crea la rama que predice la supervivencia del paciente\n",
    "    \"\"\"\n",
    "    rama_supervivencia = layers.Concatenate()([modelo, input_text])\n",
    "\n",
    "    rama_supervivencia = layers.Dense(256, activation=\"relu\")(rama_supervivencia)\n",
    "    rama_supervivencia = layers.BatchNormalization()(rama_supervivencia)\n",
    "    rama_supervivencia = layers.Dropout(0.4)(rama_supervivencia)\n",
    "    rama_supervivencia = layers.Dense(512, activation=\"relu\")(rama_supervivencia)\n",
    "    rama_supervivencia = layers.Dense(3)(rama_supervivencia)\n",
    "    rama_supervivencia = layers.Activation(\"softmax\", name=\"survival\")(rama_supervivencia)\n",
    "\n",
    "    return rama_supervivencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "input_text = layers.Input(shape=(4,))\n",
    "\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(240,240,3))\n",
    "base = base_model.output\n",
    "base = layers.GlobalAveragePooling2D()(base)\n",
    "rama_grado = crear_rama_grado(base, input_text)\n",
    "\n",
    "rama_supervivencia = crear_rama_supervivencia(base, input_text)\n",
    "\n",
    "# Model to be trained\n",
    "grade_model = Model(inputs=[base_model.input, input_text], outputs=rama_grado, name=\"grade_model\")\n",
    "survival_model = Model(inputs=[base_model.input, input_text], outputs=rama_supervivencia, name=\"survival_model\")\n",
    " \n",
    "# Training only top layers i.e. the layers which we have added in the end\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.6825 - accuracy: 0.6146 - recall: 0.6146 - val_loss: 0.9361 - val_accuracy: 0.5312 - val_recall: 0.5312\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.4567 - accuracy: 0.8047 - recall: 0.8047 - val_loss: 0.5020 - val_accuracy: 0.7604 - val_recall: 0.7604\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 61s 3s/step - loss: 0.3912 - accuracy: 0.8229 - recall: 0.8229 - val_loss: 0.5499 - val_accuracy: 0.7083 - val_recall: 0.7083\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 70s 3s/step - loss: 0.3485 - accuracy: 0.8516 - recall: 0.8516 - val_loss: 0.4713 - val_accuracy: 0.7708 - val_recall: 0.7708\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.2819 - accuracy: 0.8828 - recall: 0.8828 - val_loss: 0.3983 - val_accuracy: 0.8333 - val_recall: 0.8333\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.2369 - accuracy: 0.9401 - recall: 0.9401 - val_loss: 0.3284 - val_accuracy: 0.8750 - val_recall: 0.8750\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 61s 3s/step - loss: 0.2021 - accuracy: 0.9453 - recall: 0.9453 - val_loss: 0.2709 - val_accuracy: 0.9062 - val_recall: 0.9062\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.1787 - accuracy: 0.9479 - recall: 0.9479 - val_loss: 0.2290 - val_accuracy: 0.9167 - val_recall: 0.9167\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.1700 - accuracy: 0.9635 - recall: 0.9635 - val_loss: 0.2057 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 132s 5s/step - loss: 0.1450 - accuracy: 0.9661 - recall: 0.9661 - val_loss: 0.1986 - val_accuracy: 0.9167 - val_recall: 0.9167\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 158s 7s/step - loss: 0.1187 - accuracy: 0.9766 - recall: 0.9766 - val_loss: 0.1680 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 149s 6s/step - loss: 0.1054 - accuracy: 0.9922 - recall: 0.9922 - val_loss: 0.1881 - val_accuracy: 0.9167 - val_recall: 0.9167\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 0.0895 - accuracy: 0.9896 - recall: 0.9896 - val_loss: 0.1545 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0924 - accuracy: 0.9766 - recall: 0.9766 - val_loss: 0.1423 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0746 - accuracy: 0.9948 - recall: 0.9948 - val_loss: 0.1589 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0672 - accuracy: 0.9922 - recall: 0.9922 - val_loss: 0.1528 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0477 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 156s 7s/step - loss: 0.0542 - accuracy: 0.9948 - recall: 0.9948 - val_loss: 0.1413 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 159s 7s/step - loss: 0.0402 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9583 - val_recall: 0.9583\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 160s 7s/step - loss: 0.0396 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 160s 7s/step - loss: 0.0394 - accuracy: 0.9974 - recall: 0.9974 - val_loss: 0.1441 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 143s 6s/step - loss: 0.0367 - accuracy: 0.9948 - recall: 0.9948 - val_loss: 0.1411 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 66s 3s/step - loss: 0.0314 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 70s 3s/step - loss: 0.0289 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9167 - val_recall: 0.9167\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.0254 - accuracy: 0.9974 - recall: 0.9974 - val_loss: 0.1472 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.0252 - accuracy: 0.9974 - recall: 0.9974 - val_loss: 0.1434 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 70s 3s/step - loss: 0.0283 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 70s 3s/step - loss: 0.0248 - accuracy: 0.9974 - recall: 0.9974 - val_loss: 0.1309 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.0229 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.0158 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.0171 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0177 - accuracy: 0.9974 - recall: 0.9974 - val_loss: 0.1453 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0140 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 67s 3s/step - loss: 0.0144 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.0129 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.0148 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.0117 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 66s 3s/step - loss: 0.0106 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9583 - val_recall: 0.9583\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 67s 3s/step - loss: 0.0114 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 125s 5s/step - loss: 0.0089 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0099 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 0.0089 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9062 - val_recall: 0.9062\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 156s 7s/step - loss: 0.0080 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9271 - val_recall: 0.9271\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 157s 7s/step - loss: 0.0055 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 0.0067 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 155s 6s/step - loss: 0.0091 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.0075 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 156s 7s/step - loss: 0.0076 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 0.0060 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9375 - val_recall: 0.9375\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 153s 6s/step - loss: 0.0058 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.0056 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9479 - val_recall: 0.9479\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.0058 - accuracy: 1.0000 - recall: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9583 - val_recall: 0.9583\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "grade_model.compile(optimizer=Adam(learning_rate=0.01), \n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics = ['accuracy', keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "valid_batch_size = 16\n",
    "train_gen = data_generator.generate_data(train_index, is_training=True, output='grade', batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_data(valid_index, is_training=True, output='grade', batch_size=valid_batch_size)\n",
    "earylyStopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, min_delta=0.01)\n",
    "Reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.01,\n",
    ")\n",
    "\n",
    "callbacks = [earylyStopping, Reducer]\n",
    "\n",
    "grade_history = grade_model.fit(train_gen,\n",
    "                    steps_per_epoch=(len(train_index)*4)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=(len(valid_index)*4)//valid_batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m Reducer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m     13\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [earylyStopping, Reducer]\n\u001b[1;32m---> 23\u001b[0m grade_history \u001b[38;5;241m=\u001b[39m \u001b[43mgrade_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:823\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 823\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    826\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2855\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2854\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2855\u001b[0m   graph_function, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3213\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(args, kwargs)\n\u001b[0;32m   3212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3213\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, args, kwargs\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3065\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3060\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3061\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3062\u001b[0m ]\n\u001b[0;32m   3063\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3064\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3076\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3077\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3078\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3079\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3081\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3082\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 986\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    991\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# We register a variable creator with reduced priority. If an outer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# variable creator is just modifying keyword arguments to the variable\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# constructor, this will work harmoniously. Since the `scope` registered\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;66;03m# better than the alternative, tracing the initialization graph but giving\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;66;03m# the user a variable type they didn't want.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:962\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 962\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    972\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:596\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    595\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\tmpamm3u63e.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:532\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    529\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_whitelisted(f):\n\u001b[1;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:340\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m    795\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 796\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    798\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    799\u001b[0m write_scalar_summaries(outputs, step\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_train_counter)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1207\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m   \u001b[38;5;66;03m# applied when when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1210\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2585\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   2942\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\n\u001b[0;32m   2943\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(),\n\u001b[0;32m   2944\u001b[0m       replica_id_in_sync_group\u001b[38;5;241m=\u001b[39mconstant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m0\u001b[39m, dtypes\u001b[38;5;241m.\u001b[39mint32)):\n\u001b[1;32m-> 2945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:255\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:532\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    529\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_whitelisted(f):\n\u001b[1;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m--> 789\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m    791\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    748\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(\n\u001b[0;32m    749\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# For custom training steps, users can just write:\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m#   trainable_variables = self.trainable_variables\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;66;03m#   gradients = tape.gradient(loss, trainable_variables)\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m#   self.optimizer.apply_gradients(zip(gradients, trainable_variables))\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# The _minimize call does a few extra steps unnecessary in most cases,\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# such as loss scaling and gradient clipping.\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m \u001b[43m_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mupdate_state(y, y_pred, sample_weight)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {m\u001b[38;5;241m.\u001b[39mname: m\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics}\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2722\u001b[0m, in \u001b[0;36m_minimize\u001b[1;34m(strategy, tape, optimizer, loss, trainable_variables)\u001b[0m\n\u001b[0;32m   2719\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, lso\u001b[38;5;241m.\u001b[39mLossScaleOptimizer):\n\u001b[0;32m   2720\u001b[0m     loss \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mget_scaled_loss(loss)\n\u001b[1;32m-> 2722\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2724\u001b[0m \u001b[38;5;66;03m# Whether to aggregate gradients outside of optimizer. This requires support\u001b[39;00m\n\u001b[0;32m   2725\u001b[0m \u001b[38;5;66;03m# of the optimizer and doesn't work with ParameterServerStrategy and\u001b[39;00m\n\u001b[0;32m   2726\u001b[0m \u001b[38;5;66;03m# CentralStroageStrategy.\u001b[39;00m\n\u001b[0;32m   2727\u001b[0m aggregate_grads_outside_optimizer \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2728\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39m_HAS_AGGREGATE_GRAD \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2729\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(strategy\u001b[38;5;241m.\u001b[39mextended,\n\u001b[0;32m   2730\u001b[0m                    parameter_server_strategy\u001b[38;5;241m.\u001b[39mParameterServerStrategyExtended))\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1067\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_gradients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1065\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> 1067\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1076\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:162\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:228\u001b[0m, in \u001b[0;36m_ConcatGradV2\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;129m@ops\u001b[39m\u001b[38;5;241m.\u001b[39mRegisterGradient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ConcatGradV2\u001b[39m(op, grad):\n\u001b[1;32m--> 228\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConcatGradHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_value_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_value_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:139\u001b[0m, in \u001b[0;36m_ConcatGradHelper\u001b[1;34m(op, grad, start_value_index, end_value_index, dim_index)\u001b[0m\n\u001b[0;32m    135\u001b[0m     concat_dim \u001b[38;5;241m=\u001b[39m constant_op\u001b[38;5;241m.\u001b[39mconstant(value\u001b[38;5;241m=\u001b[39mvalue, dtype\u001b[38;5;241m=\u001b[39mconcat_dim\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Using mod here for convenience since concat_dim is already verified\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# in concat implementation to be within the allowed [-rank, rank) range.\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m non_neg_concat_dim \u001b[38;5;241m=\u001b[39m concat_dim \u001b[38;5;241m%\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Get the inputs' tensor shapes\u001b[39;00m\n\u001b[0;32m    142\u001b[0m sizes \u001b[38;5;241m=\u001b[39m _ExtractInputShapes(input_values)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:816\u001b[0m, in \u001b[0;36mrank\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank\u001b[39m(\u001b[38;5;28minput\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    786\u001b[0m   \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m    787\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the rank of a tensor.\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m  See also `tf.shape`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 816\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrank_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:839\u001b[0m, in \u001b[0;36mrank_internal\u001b[1;34m(input, name, optimize)\u001b[0m\n\u001b[0;32m    837\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mget_shape()\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimize \u001b[38;5;129;01mand\u001b[39;00m input_shape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mrank(\u001b[38;5;28minput\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    283\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    284\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 285\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    289\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    290\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    292\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    589\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    590\u001b[0m   inputs[i] \u001b[38;5;241m=\u001b[39m inp\n\u001b[1;32m--> 591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3475\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3477\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3478\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3486\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1973\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 1974\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1975\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1976\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mG:\\Anaconda\\envs\\TFG2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1812\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1808\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1809\u001b[0m                                          serialized)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1814\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1815\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "grade_model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics = ['accuracy', keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "valid_batch_size = 16\n",
    "train_gen = data_generator.generate_data(train_index, is_training=True, output='grade', batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_data(valid_index, is_training=True, output='grade', batch_size=valid_batch_size)\n",
    "earylyStopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, min_delta=0.01)\n",
    "Reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.01,\n",
    ")\n",
    "\n",
    "callbacks = [earylyStopping, Reducer]\n",
    "\n",
    "grade_history = grade_model.fit(train_gen,\n",
    "                    steps_per_epoch=(len(train_index)*4)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=(len(valid_index)*4)//valid_batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade_model.save(\"C:/Users/Usuario/Desktop/tfg/modelos/DenseNet121-gradeFFFF.h5\")\n",
    "#survival_model.save(\"C:/Users/Usuario/Desktop/tfg/modelos/DenseNet121-survivalFFFF.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 135s 6s/step - loss: 2.4228 - accuracy: 0.3984 - recall_4: 0.3724 - val_loss: 4.0518 - val_accuracy: 0.4479 - val_recall_4: 0.4479\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 1.1392 - accuracy: 0.5104 - recall_4: 0.3333 - val_loss: 0.8366 - val_accuracy: 0.5833 - val_recall_4: 0.5312\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.8698 - accuracy: 0.6250 - recall_4: 0.4375 - val_loss: 1.6374 - val_accuracy: 0.5625 - val_recall_4: 0.5625\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.7986 - accuracy: 0.6328 - recall_4: 0.5104 - val_loss: 1.0891 - val_accuracy: 0.5833 - val_recall_4: 0.5521\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.7048 - accuracy: 0.6667 - recall_4: 0.5729 - val_loss: 1.3014 - val_accuracy: 0.5417 - val_recall_4: 0.5417\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.6532 - accuracy: 0.7240 - recall_4: 0.6406 - val_loss: 1.4487 - val_accuracy: 0.5312 - val_recall_4: 0.5104\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 153s 6s/step - loss: 0.5679 - accuracy: 0.7604 - recall_4: 0.7005 - val_loss: 0.9006 - val_accuracy: 0.6458 - val_recall_4: 0.6146\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.5132 - accuracy: 0.7786 - recall_4: 0.7344 - val_loss: 1.3103 - val_accuracy: 0.6250 - val_recall_4: 0.6250\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.5122 - accuracy: 0.8099 - recall_4: 0.7526 - val_loss: 1.5448 - val_accuracy: 0.5417 - val_recall_4: 0.5417\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.4180 - accuracy: 0.8307 - recall_4: 0.8073 - val_loss: 1.5852 - val_accuracy: 0.5625 - val_recall_4: 0.5521\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 157s 7s/step - loss: 0.4103 - accuracy: 0.8333 - recall_4: 0.8203 - val_loss: 2.2018 - val_accuracy: 0.5417 - val_recall_4: 0.5312\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.3881 - accuracy: 0.8307 - recall_4: 0.8047 - val_loss: 2.8745 - val_accuracy: 0.5625 - val_recall_4: 0.5521\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.3932 - accuracy: 0.8464 - recall_4: 0.8151 - val_loss: 1.2175 - val_accuracy: 0.6250 - val_recall_4: 0.6250\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 158s 7s/step - loss: 0.3089 - accuracy: 0.8672 - recall_4: 0.8620 - val_loss: 3.6684 - val_accuracy: 0.6042 - val_recall_4: 0.6042\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 155s 6s/step - loss: 0.3311 - accuracy: 0.8906 - recall_4: 0.8698 - val_loss: 1.4666 - val_accuracy: 0.6875 - val_recall_4: 0.6875\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 154s 6s/step - loss: 0.2987 - accuracy: 0.8646 - recall_4: 0.8516 - val_loss: 1.6585 - val_accuracy: 0.6250 - val_recall_4: 0.6250\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 156s 7s/step - loss: 0.3007 - accuracy: 0.8750 - recall_4: 0.8620 - val_loss: 2.2477 - val_accuracy: 0.5521 - val_recall_4: 0.5521\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 157s 7s/step - loss: 0.2086 - accuracy: 0.9245 - recall_4: 0.9219 - val_loss: 2.3542 - val_accuracy: 0.5938 - val_recall_4: 0.5938\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 156s 6s/step - loss: 0.2262 - accuracy: 0.9219 - recall_4: 0.9141 - val_loss: 7.4492 - val_accuracy: 0.4583 - val_recall_4: 0.4583\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 176s 7s/step - loss: 0.3669 - accuracy: 0.8958 - recall_4: 0.8932 - val_loss: 3.0858 - val_accuracy: 0.6667 - val_recall_4: 0.6667\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 162s 7s/step - loss: 0.2591 - accuracy: 0.9036 - recall_4: 0.9010 - val_loss: 2.6655 - val_accuracy: 0.6875 - val_recall_4: 0.6875\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 160s 7s/step - loss: 0.2625 - accuracy: 0.9010 - recall_4: 0.8958 - val_loss: 1.7925 - val_accuracy: 0.6771 - val_recall_4: 0.6771\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "survival_model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics = ['accuracy', keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "valid_batch_size = 16\n",
    "train_gen = data_generator.generate_data(train_index, is_training=True, output='survival', batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_data(valid_index, is_training=True, output='survival', batch_size=valid_batch_size)\n",
    "earylyStopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, min_delta=0.01)\n",
    "Reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.01,\n",
    ")\n",
    "callbacks = [earylyStopping]\n",
    "\n",
    "survival_history = survival_model.fit(train_gen,\n",
    "                    steps_per_epoch=(len(train_index)*4)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=(len(valid_index)*4)//valid_batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 88s 4s/step - loss: 1.2790 - accuracy: 0.4297 - recall_7: 0.3255 - val_loss: 2.3840 - val_accuracy: 0.4062 - val_recall_7: 0.3854\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 128s 5s/step - loss: 1.0109 - accuracy: 0.5286 - recall_7: 0.3854 - val_loss: 1.2833 - val_accuracy: 0.5000 - val_recall_7: 0.4062\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.9738 - accuracy: 0.5547 - recall_7: 0.4115 - val_loss: 1.0691 - val_accuracy: 0.5312 - val_recall_7: 0.3646\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 130s 5s/step - loss: 0.9419 - accuracy: 0.5703 - recall_7: 0.4297 - val_loss: 0.9670 - val_accuracy: 0.5000 - val_recall_7: 0.3438\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.9080 - accuracy: 0.5911 - recall_7: 0.4583 - val_loss: 0.9818 - val_accuracy: 0.4896 - val_recall_7: 0.3750\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.8713 - accuracy: 0.6042 - recall_7: 0.4479 - val_loss: 1.0130 - val_accuracy: 0.4792 - val_recall_7: 0.3646\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 131s 5s/step - loss: 0.8230 - accuracy: 0.6016 - recall_7: 0.4531 - val_loss: 0.9790 - val_accuracy: 0.5104 - val_recall_7: 0.3438\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.8348 - accuracy: 0.6068 - recall_7: 0.4583 - val_loss: 0.8908 - val_accuracy: 0.5521 - val_recall_7: 0.3438\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 128s 5s/step - loss: 0.8306 - accuracy: 0.6458 - recall_7: 0.4375 - val_loss: 1.1317 - val_accuracy: 0.4688 - val_recall_7: 0.4479\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 128s 5s/step - loss: 0.8215 - accuracy: 0.6354 - recall_7: 0.4688 - val_loss: 1.4444 - val_accuracy: 0.4688 - val_recall_7: 0.4271\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 130s 5s/step - loss: 0.8272 - accuracy: 0.6198 - recall_7: 0.4479 - val_loss: 1.1402 - val_accuracy: 0.5104 - val_recall_7: 0.4271\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 130s 5s/step - loss: 0.8001 - accuracy: 0.6172 - recall_7: 0.4661 - val_loss: 1.0843 - val_accuracy: 0.5521 - val_recall_7: 0.4583\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 127s 5s/step - loss: 0.8040 - accuracy: 0.6354 - recall_7: 0.4974 - val_loss: 1.0559 - val_accuracy: 0.5000 - val_recall_7: 0.3750\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 130s 5s/step - loss: 0.8196 - accuracy: 0.6406 - recall_7: 0.4661 - val_loss: 1.1001 - val_accuracy: 0.4271 - val_recall_7: 0.3854\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 128s 5s/step - loss: 0.7970 - accuracy: 0.6380 - recall_7: 0.4635 - val_loss: 0.8805 - val_accuracy: 0.6250 - val_recall_7: 0.4688\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.7606 - accuracy: 0.6615 - recall_7: 0.5000 - val_loss: 0.9083 - val_accuracy: 0.5833 - val_recall_7: 0.4062\n",
      "Epoch 17/100\n",
      "11/24 [============>.................] - ETA: 51s - loss: 0.7633 - accuracy: 0.6591 - recall_7: 0.4716"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "survival_model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics = ['accuracy', keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "valid_batch_size = 16\n",
    "train_gen = data_generator.generate_data(train_index, is_training=True, output='survival', batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_data(valid_index, is_training=True, output='survival', batch_size=valid_batch_size)\n",
    "earylyStopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, min_delta=0.01)\n",
    "Reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.01,\n",
    ")\n",
    "callbacks = [earylyStopping]\n",
    "\n",
    "survival_history = survival_model.fit(train_gen,\n",
    "                    steps_per_epoch=(len(train_index)*4)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen, \n",
    "                    validation_steps=(len(valid_index)*4)//valid_batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(1, 2,figsize=(16,4))\n",
    "    \n",
    "    axs[0].plot(history.history['accuracy'])\n",
    "    axs[0].plot(history.history['val_accuracy'])\n",
    "    axs[0].set_title('Precisión del modelo')\n",
    "    axs[0].set(xlabel='Epoch', ylabel='Perdida')\n",
    "    axs[0].legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
    "    \n",
    "    axs[1].plot(history.history['loss'])\n",
    "    axs[1].plot(history.history['val_loss'])\n",
    "    axs[1].set_title('Perdida del modelo')\n",
    "    axs[1].set(xlabel='Epoch', ylabel='Perdida')\n",
    "    axs[1].legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(true, pred, encoding):\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    cr_survival = classification_report(true, pred, target_names=encoding.keys())\n",
    "    print(cr_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(true, pred, encoding):\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    cf_matrix = confusion_matrix(true, pred)\n",
    "    ax = sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Blues')\n",
    "\n",
    "    ax.set_title('Matriz de confusión\\n\\n');\n",
    "    ax.set_xlabel('\\nValores predecidos')\n",
    "    ax.set_ylabel('Valores reales ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(encoding.keys(),)\n",
    "    ax.yaxis.set_ticklabels(encoding.keys(),)\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(grade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(survival_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = len(test_index)\n",
    "test_generator = data_generator.generate_data(test_index, is_training=False, output='grade', batch_size=test_batch_size )\n",
    "grade_pred = grade_model.predict(test_generator, steps=(len(test_index)*4)//test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = len(test_index)\n",
    "test_generator = data_generator.generate_data(test_index, is_training=False, output='survival', batch_size=test_batch_size )\n",
    "survival_pred = survival_model.predict(test_generator, steps=(len(test_index)*4)//test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_true = []\n",
    "index = dataframe.iloc[test_index]['grade']\n",
    "for i in index:\n",
    "    grade_true.append(i)\n",
    "    grade_true.append(i)\n",
    "    grade_true.append(i)\n",
    "    grade_true.append(i)\n",
    "\n",
    "survival_true = []\n",
    "index = dataframe.iloc[test_index]['survival_days']\n",
    "for i in index:\n",
    "    survival_true.append(i)\n",
    "    survival_true.append(i)\n",
    "    survival_true.append(i)\n",
    "    survival_true.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(grade_true, grade_pred, grade_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(grade_true, grade_pred, grade_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(survival_true, survival_pred, survival_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion(survival_true, survival_pred, survival_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
